{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from hybrid_retriever import Retriever, chunk_text_by_section, generate_embeddings_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85927f21",
   "metadata": {},
   "source": [
    "## Step 1: Load and Chunk Document\n",
    "\n",
    "Load the report.md file and split it into sections for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the report\n",
    "report_path = \"report.md\"\n",
    "if not os.path.exists(report_path):\n",
    "    print(f\"‚ùå {report_path} not found\")\n",
    "else:\n",
    "    with open(report_path, 'r', encoding='utf-8') as f:\n",
    "        report_text = f.read()\n",
    "    \n",
    "    # Chunk by sections\n",
    "    chunks = chunk_text_by_section(report_text)\n",
    "    print(f\"‚úÖ Loaded and chunked document into {len(chunks)} sections\")\n",
    "    \n",
    "    # Show first chunk\n",
    "    print(f\"\\nFirst chunk preview:\")\n",
    "    print(chunks[0][:300] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f13e30",
   "metadata": {},
   "source": [
    "## Step 2: Generate Embeddings\n",
    "\n",
    "Create embeddings for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b668082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all chunks\n",
    "embeddings = generate_embeddings_batch(chunks)\n",
    "print(f\"‚úÖ Generated {len(embeddings)} embeddings\")\n",
    "print(f\"   Embedding dimension: {len(embeddings[0]) if embeddings else 0}\")\n",
    "print(f\"   Example: {[f'{x:.4f}' for x in embeddings[0][:3]]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3595a7c",
   "metadata": {},
   "source": [
    "## Step 3: Build Hybrid Index\n",
    "\n",
    "Create a Retriever that combines semantic and lexical search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acaa035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hybrid retriever\n",
    "retriever = Retriever()\n",
    "\n",
    "# Add documents to both indexes\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    metadata = {\n",
    "        'id': i,\n",
    "        'content': chunk,\n",
    "        'section': chunk.split('\\n')[0] if chunk else f\"Section {i}\"\n",
    "    }\n",
    "    retriever.add_document(chunk, embedding, metadata)\n",
    "\n",
    "print(f\"‚úÖ Built hybrid retriever with {len(chunks)} documents\")\n",
    "print(f\"   - Vector Index: Ready for semantic search\")\n",
    "print(f\"   - BM25 Index: Ready for lexical search\")\n",
    "print(f\"   - Retriever: Ready for merged RRF search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca151b49",
   "metadata": {},
   "source": [
    "## Step 4: Test Semantic Search Only\n",
    "\n",
    "See what happens with only vector search (the original problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd955d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid_retriever import generate_embeddings_batch\n",
    "\n",
    "# Create query\n",
    "query = \"What happened with incident 2023 Q4 011\"\n",
    "query_embedding = generate_embeddings_batch([query])[0]\n",
    "\n",
    "# Semantic search only\n",
    "print(f\"üîç Query: '{query}'\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"SEMANTIC SEARCH ONLY (Original Problem)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "semantic_results = retriever.vector_index.search(query_embedding, top_k=3)\n",
    "\n",
    "for i, (metadata, distance) in enumerate(semantic_results, 1):\n",
    "    similarity = 1 - distance\n",
    "    print(f\"Result {i}: {metadata['section']}\")\n",
    "    print(f\"  Distance: {distance:.4f}, Similarity: {similarity:.4f}\")\n",
    "    print(f\"  Content: {metadata['content'][:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebd834",
   "metadata": {},
   "source": [
    "## Step 5: Test Lexical Search (BM25)\n",
    "\n",
    "See how BM25 keyword matching performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LEXICAL SEARCH (BM25)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "bm25_results = retriever.bm25_index.search(query, top_k=3)\n",
    "\n",
    "for i, (metadata, distance) in enumerate(bm25_results, 1):\n",
    "    score = -distance  # Negate to get positive score\n",
    "    print(f\"Result {i}: {metadata['section']}\")\n",
    "    print(f\"  BM25 Score: {score:.4f}\")\n",
    "    print(f\"  Content: {metadata['content'][:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30568ddb",
   "metadata": {},
   "source": [
    "## Step 6: Test Hybrid Search (Reciprocal Rank Fusion)\n",
    "\n",
    "Merge both results using RRF for improved ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6037aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"HYBRID SEARCH (RRF Fusion)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "hybrid_results = retriever.search(query, query_embedding, top_k=3)\n",
    "\n",
    "for i, (metadata, rrf_score) in enumerate(hybrid_results, 1):\n",
    "    print(f\"Result {i}: {metadata['section']}\")\n",
    "    print(f\"  RRF Score: {-rrf_score:.4f}\")\n",
    "    print(f\"  Content: {metadata['content'][:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21974117",
   "metadata": {},
   "source": [
    "## Understanding Reciprocal Rank Fusion (RRF)\n",
    "\n",
    "RRF combines rankings from multiple search systems:\n",
    "\n",
    "**Formula:** `RRF_score = 1/(k + rank)` summed across all ranking systems\n",
    "\n",
    "**Example:**\n",
    "- Semantic search returns: [Section A, Section B, Section C]\n",
    "- BM25 returns: [Section C, Section A, Section B]\n",
    "\n",
    "**RRF Calculation:**\n",
    "- Section A: 1/(60+1) + 1/(60+2) = 0.0164 + 0.0160 = 0.0324 ‚≠ê Best\n",
    "- Section B: 1/(60+2) + 1/(60+3) = 0.0160 + 0.0157 = 0.0317\n",
    "- Section C: 1/(60+3) + 1/(60+1) = 0.0157 + 0.0164 = 0.0321\n",
    "\n",
    "**Result:** Section A wins because it ranked well in both systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97613e",
   "metadata": {},
   "source": [
    "## Comparison Summary\n",
    "\n",
    "| Aspect | Semantic | Lexical (BM25) | Hybrid (RRF) |\n",
    "|--------|----------|----------------|---------------|\n",
    "| **Strengths** | Understanding context & meaning | Exact keyword matching | Both! |\n",
    "| **Weakness** | Misses exact keywords | No semantic understanding | Requires both |\n",
    "| **Problem Query** | Returns irrelevant sections | May miss nuance | Returns best of both |\n",
    "| **Architecture** | VectorIndex | BM25Index | Retriever + RRF |\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "By combining semantic search (embeddings) with lexical search (BM25), we get:\n",
    "- ‚úÖ Semantic understanding\n",
    "- ‚úÖ Exact keyword matching  \n",
    "- ‚úÖ Robust ranking via RRF\n",
    "\n",
    "This is the foundation of production RAG systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf665d11",
   "metadata": {},
   "source": [
    "## Why This Design is Extensible\n",
    "\n",
    "The Retriever pattern makes it easy to add more search methods:\n",
    "\n",
    "```python\n",
    "class MyCustomIndex:\n",
    "    def add_document(self, text, metadata):\n",
    "        # Your implementation\n",
    "        pass\n",
    "    \n",
    "    def search(self, query, top_k):\n",
    "        # Your implementation\n",
    "        return [(metadata, distance), ...]\n",
    "\n",
    "# Just add it to Retriever!\n",
    "retriever.custom_index = MyCustomIndex()\n",
    "retriever.search()  # Automatically includes custom results via RRF\n",
    "```\n",
    "\n",
    "As long as each index has `add_document()` and `search()`, it works with RRF!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
